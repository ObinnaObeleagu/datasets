{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference_pytorch",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayoolaolafenwa/Oranges_datasets/blob/master/inference_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVpClBIw2RB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0ce74331-dfcb-4b6a-c309-93daae4197aa"
      },
      "source": [
        "!wget https://github.com/ayoolaolafenwa/Oranges_datasets/releases/download/0.1/pytorch_trained.model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-10 03:05:19--  https://github.com/ayoolaolafenwa/Oranges_datasets/releases/download/0.1/pytorch_trained.model\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/207338810/bc856f00-1b01-11ea-81f5-d7a311ea46ff?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191210T030519Z&X-Amz-Expires=300&X-Amz-Signature=c4e098e74c2dd7655211a933ff69399c0f2b6cdb6e2249126625980f9d4987d0&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dpytorch_trained.model&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-12-10 03:05:19--  https://github-production-release-asset-2e65be.s3.amazonaws.com/207338810/bc856f00-1b01-11ea-81f5-d7a311ea46ff?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191210T030519Z&X-Amz-Expires=300&X-Amz-Signature=c4e098e74c2dd7655211a933ff69399c0f2b6cdb6e2249126625980f9d4987d0&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dpytorch_trained.model&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.41.76\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.41.76|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8653576 (8.3M) [application/octet-stream]\n",
            "Saving to: ‘pytorch_trained.model’\n",
            "\n",
            "\rpytorch_trained.mod   0%[                    ]       0  --.-KB/s               \rpytorch_trained.mod   1%[                    ] 126.57K   502KB/s               \rpytorch_trained.mod  13%[=>                  ]   1.12M  2.22MB/s               \rpytorch_trained.mod  90%[=================>  ]   7.44M  9.83MB/s               \rpytorch_trained.mod 100%[===================>]   8.25M  10.8MB/s    in 0.8s    \n",
            "\n",
            "2019-12-10 03:05:20 (10.8 MB/s) - ‘pytorch_trained.model’ saved [8653576/8653576]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0QGgBckxOlh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d00616b5-fd9f-460f-f2a3-a1945a0ce88d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import numpy \n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class Unit(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Unit, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size =3, stride = 1, padding = 1)\n",
        "        self.bn = nn.BatchNorm2d(num_features = out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        output = self.bn(output) \n",
        "        output = self.relu(output)   \n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class Custom_class(nn.Module):\n",
        "    def __init__(self, num_classes = 2):\n",
        "        super(Custom_class, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            \n",
        "          Unit(in_channels = 3, out_channels = 32),\n",
        "\n",
        "          nn.MaxPool2d(kernel_size = 2,stride=2), #224 becomes 112\n",
        "\n",
        "          Unit(in_channels = 32, out_channels = 32),\n",
        "          Unit(in_channels = 32, out_channels = 32),\n",
        "          Unit(in_channels = 32, out_channels = 32),\n",
        "\n",
        "          nn.MaxPool2d(kernel_size = 2,stride=2), #112 becomes 56\n",
        "\n",
        "          Unit(in_channels = 32, out_channels = 64),\n",
        "          Unit(in_channels = 64, out_channels = 64),\n",
        "          Unit(in_channels = 64, out_channels = 64),\n",
        "          Unit(in_channels = 64, out_channels = 64),\n",
        "\n",
        "          nn.MaxPool2d(kernel_size = 2, stride=2), # 56 becomes 28\n",
        "\n",
        "          Unit(in_channels = 64, out_channels = 128),\n",
        "          Unit(in_channels = 128, out_channels = 128),\n",
        "          Unit(in_channels = 128, out_channels = 128),\n",
        "          Unit(in_channels = 128, out_channels = 128),\n",
        "\n",
        "          nn.MaxPool2d(kernel_size = 2, stride=2), # 28 becomes 14\n",
        "\n",
        "          Unit(in_channels = 128, out_channels = 256),\n",
        "          Unit(in_channels = 256, out_channels = 256),\n",
        "          Unit(in_channels = 256, out_channels = 256),\n",
        "\n",
        "          nn.AvgPool2d(kernel_size = 14) # use 14 here\n",
        "        )\n",
        "\n",
        "        self.fc =  nn.Linear(in_features = 256, out_features = num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.net(input)\n",
        "        output = output.view(-1, 256)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def load_model(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "    model.eval()\n",
        "\n",
        "    model =  load_model(\"pytorch_trained.model\")      \n",
        "\n",
        "    return model\n",
        "model = Custom_class(num_classes=2)\n",
        "  \n",
        "\n",
        "\n",
        "def predict_image(image_path):\n",
        "    #print(\"Prediction in progress\")\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Define transformations for the image, should (note that imagenet models are trained with image size 224)\n",
        "    transformation = transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "    ])\n",
        "\n",
        "    # Preprocess the image\n",
        "    image_tensor = transformation(image).float()\n",
        "\n",
        "    # Add an extra batch dimension since pytorch treats all images as batches\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        image_tensor.cuda()\n",
        "        \n",
        "    # Turn the input into a Variable\n",
        "    input = Variable(image_tensor)\n",
        "\n",
        "    # Predict the class of the image\n",
        "    output = model(input)\n",
        "\n",
        "\n",
        "    index = output.data.numpy().argmax()\n",
        "    \n",
        "    \n",
        "    return index\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    imagefile = \"unripe8.jpg\"\n",
        "\n",
        "    imagepath = os.path.join(os.getcwd(), imagefile)\n",
        "\n",
        "    class_map = {0:\"ripe orange\", 1:\"unripe orange\"}\n",
        "    # run prediction function annd obtain prediccted class index\n",
        "    index = predict_image(imagepath)\n",
        "    confidence = predict_image(imagepath)\n",
        "    \n",
        "    predicted_class =class_map[index]\n",
        "    \n",
        "    \n",
        "\n",
        "    print(\"Class Name: \", predicted_class) \n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Name:  unripe orange\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}